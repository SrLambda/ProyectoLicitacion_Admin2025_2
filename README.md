# üèõÔ∏è Sistema de Gesti√≥n de Causas Judiciales

## Informaci√≥n del Proyecto

### Licitaci√≥n
- **C√≥digo**: 1552-56-LE25
- **Nombre**: Sistema Inform√°tico de Gesti√≥n de Causas Judiciales para Servicio de salud de Atacama
- **Link**: [Ver licitaci√≥n en Mercado P√∫blico](http://www.mercadopublico.cl/Procurement/Modules/RFB/DetailsAcquisition.aspx?qs=tyy5Bzwfkbwk7fVwIC5aDA==)

### Integrantes del Equipo
- Camilo Fuentes
- Demian Maturana
- Catalina Herrera

### ¬øQu√© resuelve este sistema?
El sistema moderniza y digitaliza la gesti√≥n integral de causas judiciales, proporcionando una plataforma web centralizada que permite:
- Registro y seguimiento de procesos judiciales
- Gesti√≥n documental completa
- Notificaciones autom√°ticas a las partes
- Generaci√≥n de reportes y estad√≠sticas
- Control de acceso seg√∫n roles y permisos
- An√°lisis de seguridad con IA

---

## Arquitectura del Sistema

### Diagrama de Arquitectura
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                         USUARIOS FINALES                        ‚îÇ
‚îÇ              (Jueces, Abogados, Administrativos)                ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ HTTPS
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    FRONTEND (React + Nginx)                      ‚îÇ
‚îÇ                         2 R√©plicas (HA)                          ‚îÇ
‚îÇ  frontend-1: :80  ‚îÇ  frontend-2: :80  ‚îÇ  Load Balanced           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ frontend-network
                           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  API GATEWAY (Traefik v2.10)                    ‚îÇ
‚îÇ           - Load Balancing  - Service Discovery                 ‚îÇ
‚îÇ           - SSL Termination - Rate Limiting                     ‚îÇ
‚îÇ                    Dashboard: :8080                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
      ‚îÇ        ‚îÇ        ‚îÇ        ‚îÇ        ‚îÇ        ‚îÇ backend-network
      ‚ñº        ‚ñº        ‚ñº        ‚ñº        ‚ñº        ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Auth   ‚îÇ ‚îÇ  Casos  ‚îÇ ‚îÇDocumentos‚îÇ ‚îÇNotificac.‚îÇ ‚îÇ    AI    ‚îÇ
‚îÇ Service ‚îÇ ‚îÇ Service ‚îÇ ‚îÇ Service  ‚îÇ ‚îÇ Service  ‚îÇ ‚îÇ Service  ‚îÇ
‚îÇ  :5001  ‚îÇ ‚îÇ  :5002  ‚îÇ ‚îÇ  :5003   ‚îÇ ‚îÇ  :5004   ‚îÇ ‚îÇ  :5005   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
     ‚îÇ           ‚îÇ           ‚îÇ            ‚îÇ            ‚îÇ
     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ database-network
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ                 ‚îÇ                 ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  MySQL   ‚îÇ     ‚îÇ   Redis   ‚îÇ    ‚îÇ  Storage  ‚îÇ
    ‚îÇ  Master  ‚îÇ     ‚îÇ  Master   ‚îÇ    ‚îÇ  (Docs)   ‚îÇ
    ‚îÇ  :3306   ‚îÇ     ‚îÇ   :6379   ‚îÇ    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ                 ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  MySQL   ‚îÇ     ‚îÇ   Redis   ‚îÇ
    ‚îÇ  Replica ‚îÇ     ‚îÇ  Replica  ‚îÇ
    ‚îÇ  :3307   ‚îÇ     ‚îÇ   :6380   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  MONITOREO & OBSERVABILIDAD                      ‚îÇ
‚îÇ  Prometheus (:9090)  ‚îÇ  Grafana (:3000)  ‚îÇ  Logs Centralizados   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    BACKUP & RECUPERACI√ìN                         ‚îÇ
‚îÇ         Backup Service - Respaldos automatizados diarios         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Servicios Implementados (14 servicios totales)

#### Frontend (Alta Disponibilidad)
1. **Frontend-1** (React + Nginx) - Primera r√©plica
2. **Frontend-2** (React + Nginx) - Segunda r√©plica

#### API Gateway
3. **Gateway** (Traefik) - Enrutamiento y Load Balancing

#### Microservicios Backend
4. **Auth Service** - Autenticaci√≥n y gesti√≥n de usuarios/roles
5. **Casos Service** - CRUD de causas judiciales (Core del sistema)
6. **Documentos Service** - Gesti√≥n de archivos y documentos
7. **Notificaciones Service** - Alertas y notificaciones autom√°ticas
8. **AI Service** - An√°lisis de seguridad con IA

#### Bases de Datos (Alta Disponibilidad)
9. **MySQL Master** - Base de datos principal
10. **MySQL Replica** - R√©plica para lectura y failover
11. **Redis Master** - Cach√© principal
12. **Redis Replica** - R√©plica de cach√©

#### Monitoreo
13. **Prometheus** - Recolecci√≥n de m√©tricas
14. **Grafana** - Visualizaci√≥n de dashboards

#### Infraestructura
15. **Backup Service** - Respaldos automatizados

### Redes Docker (3 redes personalizadas)
- **frontend-network**: Comunicaci√≥n Frontend ‚Üî Gateway
- **backend-network**: Comunicaci√≥n entre microservicios
- **database-network**: Acceso seguro a bases de datos

### Tecnolog√≠as Utilizadas

| Componente | Tecnolog√≠a | Justificaci√≥n |
|------------|-----------|---------------|
| **Orquestaci√≥n** | Docker Compose | Requisito obligatorio del proyecto |
| **API Gateway** | Traefik | Load balancing autom√°tico y configuraci√≥n simple |
| **Backend** | Python (FastAPI) | Alto rendimiento para APIs REST |
| **Frontend** | React + Nginx | SPA moderna con servidor web robusto |
| **BD Principal** | MySQL 8.0 | Replicaci√≥n Master-Replica para HA |
| **Cach√©** | Redis 7 | Alto rendimiento con soporte para Sentinel |
| **Monitoreo** | Prometheus + Grafana | Est√°ndar de la industria |
| **IA** | Ollama (Llama2) | An√°lisis de seguridad en logs |

---

## Alta Disponibilidad (HA)

### Estrategias Implementadas

#### 1. Replicaci√≥n de Base de Datos MySQL
- **Configuraci√≥n**: 1 Master + 1 Replica
- **Tipo**: Streaming Replication
- **Failover**: Autom√°tico mediante health checks
- **Beneficio**: Si cae el Master, la Replica toma el control

#### 2. Replicaci√≥n de Redis
- **Configuraci√≥n**: 1 Master + 1 Replica
- **Tipo**: Master-Slave replication
- **Beneficio**: Lectura distribuida y recuperaci√≥n r√°pida

#### 3. M√∫ltiples R√©plicas de Frontend
- **Configuraci√≥n**: 2 r√©plicas independientes
- **Load Balancer**: Traefik distribuye el tr√°fico
- **Beneficio**: Si cae una r√©plica, la otra mantiene el servicio

#### 4. Health Checks en Todos los Servicios
- Monitoreo constante del estado de cada contenedor
- Restart autom√°tico si un servicio falla
- Dependencias configuradas con `condition: service_healthy`

### Demostraci√≥n de HA
Durante la presentaci√≥n se mostrar√°:
1. Sistema funcionando con todas las r√©plicas activas
2. Detener manualmente una r√©plica de MySQL
3. Sistema contin√∫a operando sin interrupciones
4. R√©plica se recupera autom√°ticamente

---

## üîÑ Sistema de Failover y Failback Autom√°tico

### Descripci√≥n General

El sistema incluye **automatizaci√≥n completa de failover y failback** para garantizar alta disponibilidad de la base de datos. En caso de que el servidor Master (primario) falle, la Replica (esclavo) se promueve autom√°ticamente como nuevo Master.

### Tabla de Contenidos de Failover/Failback
1. [Conceptos Clave](#conceptos-clave-failover)
2. [Arquitectura](#arquitectura-de-failover-1)
3. [Scripts Disponibles](#scripts-disponibles-failover)
4. [Procedimiento Completo](#procedimiento-completo-failover-failback)
5. [Monitoreo](#monitoreo-y-validaci√≥n-1)
6. [Troubleshooting](#troubleshooting-failover)

### Arquitectura de Failover

```
Estado Normal:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  db-master   ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÇ  db-proxy    ‚îÇ
‚îÇ   :3306      ‚îÇ         ‚îÇ   :6033      ‚îÇ
‚îÇ (WRITE/READ) ‚îÇ         ‚îÇ (LOAD BALANCE)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚ñ≤                         ‚ñ≤
       ‚îÇ                         ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ Monitoreo activo ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
              (health checks)

Estado de Failover (Master cae):
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  db-master   ‚îÇ ‚úó CA√çDA ‚îÇ  db-proxy    ‚îÇ
‚îÇ   OFFLINE    ‚îÇ         ‚îÇ   SWITCHING  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                ‚îÇ
                                ‚ñº
                         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                         ‚îÇ  db-slave    ‚îÇ
                         ‚îÇ PROMOVIDO    ‚îÇ
                         ‚îÇ (NUEVO MASTER)
                         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Componentes del Sistema

#### 1. **ProxySQL (db-proxy:6033)**
- Monitorea continuamente la salud de db-master y db-slave
- Enruta autom√°ticamente el tr√°fico al servidor disponible
- Soporta 2 hostgroups:
  - **Hostgroup 10**: Master (escritura)
  - **Hostgroup 20**: Slave/Replica (lectura)

#### 2. **Failover Daemon** (Auto-activado)
```bash
Container: failover-daemon
Script: scripts/auto-failover-daemon.sh
```
- Monitorea cada 5 segundos si db-master est√° activo
- Ejecuta autom√°ticamente la promoci√≥n del slave si master cae
- Modifica docker-compose.yml para actualizar las r√©plicas

#### 3. **Failback Daemon** (Opcional, requiere perfil)
```bash
Container: failback-daemon (perfil: failback)
Script: scripts/auto-failback-daemon.sh
```
- Monitorea si el Master original se recupera
- Reinicia la replicaci√≥n de forma segura
- Evita conflictos y p√©rdida de datos

### C√≥mo Funciona el Failover Autom√°tico

#### Detecci√≥n de Falla
```bash
1. ProxySQL intenta conectar a db-master cada segundo
2. Tres intentos fallidos = Master considerado DOWN
3. Activa el proceso de failover
```

#### Proceso de Failover
```bash
1. failover-daemon detecta que db-master est√° ca√≠do
2. Ejecuta: docker exec db-slave mysql -e "STOP REPLICA"
3. Ejecuta: docker exec db-slave mysql -e "RESET REPLICA ALL"
4. Ejecuta: docker exec db-slave mysql -e "SET GLOBAL read_only=0"
5. Actualiza docker-compose.yml:
   - Cambia db-master a "paused: true"
   - Configura db-slave como nuevo master
6. ProxySQL detecta cambios y redirige tr√°fico
7. El sistema contin√∫a funcionando con el nuevo Master
```

### Instrucciones de Uso

#### 1. Monitoreo del Estado Actual
```bash
# Ver estado de la replicaci√≥n
docker exec db-slave mysql -u root -p${MYSQL_ROOT_PASSWORD} -e "SHOW REPLICA STATUS\G"

# Ver estad√≠sticas de ProxySQL
docker exec -it db-proxy proxysql-admin --config-file=/etc/proxysql/proxysql.cnf
```

#### 2. Simular una Falla (Prueba de Failover)
```bash
# Detener el Master deliberadamente
docker compose stop db-master

# Esperar 5-10 segundos...

# Verificar que el slave fue promovido
docker compose logs failover-daemon | tail -20

# Ver que el sistema contin√∫a funcionando
curl http://localhost:8081/api/casos
```

#### 3. Recuperaci√≥n Manual del Master Original

**Opci√≥n A: Sin Failback Autom√°tico**
```bash
# 1. Reiniciar el Master
docker compose start db-master

# 2. Esperar a que est√© listo (~30 segundos)
docker compose exec db-master mysqladmin ping -u root -p${MYSQL_ROOT_PASSWORD}

# 3. Reconfigurar manualmente la replicaci√≥n
docker compose exec db-master mysql -u root -p${MYSQL_ROOT_PASSWORD} -e \
  "CHANGE REPLICATION SOURCE TO SOURCE_HOST='db-slave', SOURCE_USER='replicator', SOURCE_PASSWORD='${MYSQL_REPLICATION_PASSWORD}'"

docker compose exec db-master mysql -u root -p${MYSQL_ROOT_PASSWORD} -e \
  "SET GLOBAL read_only=1; START REPLICA"

# 4. Actualizar docker-compose.yml para restaurar configuraci√≥n original
# (Cambiar db-slave back a replica)
```

**Opci√≥n B: Con Failback Autom√°tico**
```bash
# 1. Activar el daemon de failback
docker compose --profile failback up -d failback-daemon

# 2. Reiniciar el Master
docker compose start db-master

# 3. El failback-daemon autom√°ticamente:
#    - Detecta que db-master se recuper√≥
#    - Copia datos del nuevo master al antiguo
#    - Reconfigura la replicaci√≥n
#    - Promueve db-master como master nuevamente
#    - Detiene failback-daemon (autocompletado)

# 4. Verificar estado final
docker compose exec db-master mysql -u root -p${MYSQL_ROOT_PASSWORD} -e "SHOW MASTER STATUS\G"
```

#### 4. Forzar un Failover Manual (Si es Necesario)
```bash
# ADVERTENCIA: Esto rompe la replicaci√≥n. Solo usar en emergencias.

# 1. Promover el slave
docker exec db-slave mysql -u root -p${MYSQL_ROOT_PASSWORD} -e "STOP REPLICA; RESET REPLICA ALL; SET GLOBAL read_only=0"

# 2. Actualizar aplicaci√≥n para usar nuevo master
# (Cambiar DATABASE_URL en servicios a apuntar a db-slave)

# 3. Luego, cuando master se recupere, sincronizar desde backup
scripts/restore-db.sh --latest
```

### Scripts Disponibles

| Script | Ubicaci√≥n | Funci√≥n |
|--------|-----------|---------|
| `auto-failover-daemon.sh` | `scripts/auto-failover-daemon.sh` | Monitorea y promueve replica en caso de falla del master |
| `auto-failback-daemon.sh` | `scripts/auto-failback-daemon.sh` | Restaura master cuando se recupera (opcional) |
| `failover-promote-slave.sh` | `scripts/failover-promote-slave.sh` | Promueve replica manualmente |
| `failback-restore-master.sh` | `scripts/failback-restore-master.sh` | Restaura configuraci√≥n original del master |
| `check-replication-status.sh` | `scripts/check-replication-status.sh` | Verifica estado actual de replicaci√≥n |

### Verificar Estado de Failover

```bash
# Ver logs del daemon de failover
docker compose logs failover-daemon

# Buscar eventos de failover
docker compose logs failover-daemon | grep -i "failover\|promote"

# Ver cambios en docker-compose.yml
git diff docker-compose.yml

# Verificar que db-proxy est√° enrutando correctamente
docker exec -it db-proxy mysql -h localhost -u admin -padmin -e "SHOW PROCESSLIST"
```

### Monitoreo con Prometheus/Grafana

Los eventos de failover se registran y pueden monitorearse en Grafana:

```bash
# Acceder a Grafana
http://localhost:3000

# Dashboard: "Base de Datos - Replicaci√≥n"
# Buscar m√©tricas:
- mysql_global_status_threads_running (cambio en master)
- mysql_global_status_read_only (cambio a read_only=0)
- proxysql_mysql_monitor_errors (errores de conexi√≥n)
```

### Mejores Pr√°cticas

1. **Mantener backups actualizados**
   ```bash
   # Ejecutar backups regularmente
   scripts/backup/backup-db.sh
   ```

2. **Probar failover regularmente**
   ```bash
   # Una vez al mes, simular una falla en control y confirmar que el sistema se recupera
   ```

3. **Monitorear logs**
   ```bash
   # Revisar regularmente los logs de failover
   docker compose logs -f failover-daemon
   ```

4. **Actualizar credenciales en ProxySQL**
   ```bash
   # Si cambia MYSQL_MONITOR_PASSWORD, actualizar:
   # scripts/config-templates/proxysql/proxysql.cnf.template
   # Luego regenerar config: scripts/init-proxysql.sh
   ```

### Troubleshooting

**Problema: Failover no se ejecuta autom√°ticamente**
```bash
# Verificar que failover-daemon est√° corriendo
docker compose ps failover-daemon

# Ver logs del daemon
docker compose logs failover-daemon

# Verificar que ProxySQL est√° monitoreando
docker compose exec db-proxy proxysql-admin --check-status
```

**Problema: ProxySQL no reconoce cambios**
```bash
# Reiniciar ProxySQL
docker compose restart db-proxy

# Esperar 10 segundos para que reconecte
sleep 10

# Verificar status
docker compose exec db-proxy proxysql-admin --config-file=/etc/proxysql/proxysql.cnf
```

**Problema: Replicaci√≥n rota despu√©s de failback**
```bash
# Detener ambos servidores
docker compose stop db-master db-slave

# Reiniciar limpio
docker compose up -d db-master db-slave

# Verificar replicaci√≥n
docker compose exec db-slave mysql -u root -p${MYSQL_ROOT_PASSWORD} -e "SHOW REPLICA STATUS\G"
```

---

## üìã Referencia Completa de Scripts de Failover/Failback

### 1. `check-replication-status.sh` - Verificar Estado de Replicaci√≥n

**Ubicaci√≥n:** `scripts/check-replication-status.sh`

**Descripci√≥n:** Script para monitorear la salud general de la replicaci√≥n MySQL y ProxySQL.

**Uso b√°sico:**
```bash
# Hacer el script ejecutable (solo la primera vez)
chmod +x scripts/check-replication-status.sh

# Ejecutar el script
./scripts/check-replication-status.sh
```

**¬øQu√© verifica?**
- Estado de los servidores en ProxySQL (Master, Slave)
- Status del thread replicador
- Lag de replicaci√≥n
- Errores en la replicaci√≥n
- Conexiones activas

**Salida esperada:**
```
==========================================
Database Replication Health Check
==========================================

=== ProxySQL Server Status ===
hostgroup_id | hostname  | port | status | weight | max_connections
10           | db-master | 3306 | ONLINE | 1      | 100
20           | db-master | 3306 | ONLINE | 1      | 100
20           | db-slave  | 3306 | ONLINE | 1      | 100

=== Master Replication Status ===
(Informaci√≥n del master)

=== Slave Replication Status ===
Slave_IO_Running: Yes
Slave_SQL_Running: Yes
Seconds_Behind_Master: 0
```

**Interpretar resultados:**
- ‚úÖ `ONLINE` en ambos servidores = Replicaci√≥n sana
- ‚ùå `OFFLINE` en db-slave = Falla detectada, failover debe activarse
- ‚ö†Ô∏è `Seconds_Behind_Master > 10` = Lag alto, investigar carga en slave

---

### 2. `failover-promote-slave.sh` - Promover Slave Manualmente

**Ubicaci√≥n:** `scripts/failover-promote-slave.sh`

**Descripci√≥n:** Script para promover manualmente el Slave como nuevo Master (ejecutar failover manual).

**‚ö†Ô∏è ADVERTENCIA:** Este script rompe la replicaci√≥n. Solo usar cuando:
- El Master est√° permanentemente ca√≠do
- El failover autom√°tico no se ejecut√≥
- Se necesita forzar un cambio de master

**Uso:**
```bash
# Hacer el script ejecutable
chmod +x scripts/failover-promote-slave.sh

# Ejecutar el failover
./scripts/failover-promote-slave.sh
```

**Proceso que ejecuta:**
1. Verifica que el Slave est√° sano
2. Detiene la replicaci√≥n en el Slave
3. Promueve el Slave como nuevo Master (`read_only = OFF`)
4. Actualiza ProxySQL para cambiar hostgroups
5. Verifica que ProxySQL reconoce los cambios
6. Redirige el tr√°fico al nuevo Master

**Ejemplo de ejecuci√≥n:**
```bash
$ ./scripts/failover-promote-slave.sh

==========================================
ProxySQL Failover: Promote Slave to Master
==========================================

Verificando estado actual de ProxySQL...
hostgroup_id | hostname | status
10           | db-master| OFFLINE
20           | db-master| OFFLINE
20           | db-slave | ONLINE

‚úì Deteniendo replicaci√≥n en db-slave...
‚úì Promoviendo db-slave como nuevo Master...
‚úì Actualizando ProxySQL...
‚úì Verificando cambios...

‚úÖ Failover completado exitosamente
    Nuevo Master: db-slave
    Los clientes ahora est√°n conectados a db-slave
```

**Verificar despu√©s:**
```bash
# Confirmar que ProxySQL cambi√≥
./scripts/check-replication-status.sh

# Ver que las aplicaciones siguen funcionando
curl http://localhost:8081/api/casos
```

---

### 3. `failback-restore-master.sh` - Restaurar Master Original

**Ubicaci√≥n:** `scripts/failback-restore-master.sh`

**Descripci√≥n:** Script para restaurar la configuraci√≥n original despu√©s de un failover (convertir db-master nuevamente en Master y db-slave en Replica).

**‚ö†Ô∏è REQUIERE:** Que db-master est√© nuevamente disponible y sincronizado con datos del nuevo master.

**Uso:**
```bash
# Hacer el script ejecutable
chmod +x scripts/failback-restore-master.sh

# Ejecutar el failback
./scripts/failback-restore-master.sh
```

**Proceso que ejecuta:**
1. Verifica que db-master est√© disponible
2. Sincroniza datos desde el nuevo master a db-master (si es necesario)
3. Configura db-master como nuevo Slave del actual Master (db-slave)
4. Espera a que se sincronice completamente
5. Promueve db-master a Master (`read_only = OFF`)
6. Actualiza ProxySQL para volver a la configuraci√≥n original
7. Verifica la integridad de la replicaci√≥n

**Ejemplo de ejecuci√≥n:**
```bash
$ ./scripts/failback-restore-master.sh

==========================================
ProxySQL Failback: Restore Original Master
==========================================

‚úì Verificando disponibilidad de db-master...
‚úì Sincronizando datos...
‚úì Configurando replicaci√≥n...
‚úì Esperando sincronizaci√≥n (Lag: 5s)...
‚úì Esperando sincronizaci√≥n (Lag: 0s)...
‚úì Promoviendo db-master...
‚úì Actualizando ProxySQL...

‚úÖ Failback completado exitosamente
    Master Principal: db-master
    Replica: db-slave
    Sistema restaurado a configuraci√≥n original
```

**Verificar despu√©s:**
```bash
# Confirmar que ProxySQL volvi√≥ a la config original
./scripts/check-replication-status.sh

# Verificar que db-master es Master
docker exec db-master mysql -u root -p${MYSQL_ROOT_PASSWORD} -e "SHOW MASTER STATUS\G"

# Verificar que db-slave es Slave
docker exec db-slave mysql -u root -p${MYSQL_ROOT_PASSWORD} -e "SHOW REPLICA STATUS\G"
```

---

### 4. `auto-failover-daemon.sh` - Daemon de Failover Autom√°tico

**Ubicaci√≥n:** `scripts/auto-failover-daemon.sh`

**Descripci√≥n:** Daemon que monitorea continuamente la salud del Master y ejecuta failover autom√°ticamente si falla.

**Nota:** Normalmente se ejecuta en contenedor (`failover-daemon` en docker-compose.yml)

**Uso desde l√≠nea de comandos:**
```bash
# Hacer el script ejecutable
chmod +x scripts/auto-failover-daemon.sh

# Ejecutar el daemon (se ejecutar√° indefinidamente)
./scripts/auto-failover-daemon.sh

# O en background
./scripts/auto-failover-daemon.sh &

# Ver logs
tail -f /tmp/failover-daemon.log
```

**Variables de configuraci√≥n (.env):**
```bash
FAILOVER_CHECK_INTERVAL=5          # Verificar cada 5 segundos
FAILOVER_FAILURE_THRESHOLD=3       # Fallar 3 veces = activar failover
FAILOVER_LOG_FILE=/tmp/failover.log
```

**¬øQu√© hace?**
1. Lee variables del `.env`
2. Entra en un loop infinito
3. Cada 5 segundos intenta conectar a db-master
4. Si falla 3 veces consecutivas, ejecuta `failover-promote-slave.sh`
5. Registra toda la actividad en logs

**Monitorar el daemon:**
```bash
# Ver si est√° corriendo
docker compose ps failover-daemon

# Ver logs en tiempo real
docker compose logs -f failover-daemon

# Buscar eventos de failover en logs
docker compose logs failover-daemon | grep -i "failover\|promote"
```

---

### 5. `auto-failback-daemon.sh` - Daemon de Failback Autom√°tico (Opcional)

**Ubicaci√≥n:** `scripts/auto-failback-daemon.sh`

**Descripci√≥n:** Daemon que monitorea si el Master original se recupera y ejecuta failback autom√°ticamente.

**‚ö†Ô∏è OPCIONAL:** Solo se ejecuta si se activa el perfil `failback`

**Uso:**
```bash
# Activar el daemon de failback (con perfil)
docker compose --profile failback up -d failback-daemon

# Verificar que est√° corriendo
docker compose ps failback-daemon

# Ver logs
docker compose logs -f failback-daemon

# Detener el daemon cuando se completa el failback
docker compose --profile failback down failback-daemon
```

**¬øQu√© hace?**
1. Monitorea si db-master se recupera
2. Detecta cuando db-master est√° disponible
3. Sincroniza datos desde db-slave a db-master
4. Reconfigura la replicaci√≥n
5. Promueve db-master como Master nuevamente
6. Se detiene autom√°ticamente

**Salida en logs:**
```
Iniciando failback daemon...
Esperando recuperaci√≥n del Master original...
Master db-master detectado - iniciando failback
Sincronizando datos...
Failback completado - db-master es Master nuevamente
```

---

### 6. `auto-failover-host.sh` - Failover en Host (No Contenedor)

**Ubicaci√≥n:** `scripts/auto-failover-host.sh`

**Descripci√≥n:** Versi√≥n del failover daemon para ejecutarse en el HOST como servicio systemd o supervisord (no en contenedor).

**Cu√°ndo usar:**
- Cuando quieres que el failover funcione incluso si el contenedor del daemon falla
- Para m√°xima resiliencia

**Instalaci√≥n como servicio systemd:**
```bash
# 1. Copiar script a /usr/local/bin
sudo cp scripts/auto-failover-host.sh /usr/local/bin/

# 2. Dar permisos de ejecuci√≥n
sudo chmod +x /usr/local/bin/auto-failover-host.sh

# 3. Copiar archivo systemd
sudo cp scripts/systemd/auto-failover.service /etc/systemd/system/

# 4. Recargar systemd
sudo systemctl daemon-reload

# 5. Habilitar el servicio
sudo systemctl enable auto-failover.service

# 6. Iniciar el servicio
sudo systemctl start auto-failover.service

# 7. Verificar estado
sudo systemctl status auto-failover.service

# 8. Ver logs
sudo journalctl -u auto-failover.service -f
```

**Comandos √∫tiles:**
```bash
# Ver estado
sudo systemctl status auto-failover.service

# Reiniciar
sudo systemctl restart auto-failover.service

# Detener
sudo systemctl stop auto-failover.service

# Ver √∫ltimos 50 logs
sudo journalctl -u auto-failover.service -n 50

# Monitoreo en tiempo real
sudo journalctl -u auto-failover.service -f
```

---

## üöÄ Flujo de Trabajo T√≠pico: Failover y Failback

### Escenario: Master falla durante producci√≥n

**Paso 1: Detecci√≥n autom√°tica (autom√°tico)**
```bash
failover-daemon detecta ca√≠da de db-master
‚Üí Ejecuta failover-promote-slave.sh autom√°ticamente
‚Üí db-slave se promueve como nuevo Master
```

**Paso 2: Verificar estado (manual)**
```bash
./scripts/check-replication-status.sh
# Confirmar que db-slave ahora es Master
```

**Paso 3: Reparar Master original (operacional)**
```bash
# Ejemplo: reiniciar db-master
docker compose restart db-master

# Esperar a que est√© listo
sleep 30
```

**Paso 4: Restaurar configuraci√≥n original (manual)**
```bash
./scripts/failback-restore-master.sh
# db-master vuelve a ser Master
# db-slave vuelve a ser Replica
```

**Paso 5: Verificar integridad (manual)**
```bash
./scripts/check-replication-status.sh
# Confirmar que replicaci√≥n est√° sana
# Ambos threads (IO y SQL) deben estar running
```

---

## üìä Integraci√≥n con Monitoreo

### Ver eventos de failover en Grafana

```bash
# 1. Acceder a Grafana
http://localhost:3000

# 2. Ir a Dashboard ‚Üí "Base de Datos - Replicaci√≥n"

# 3. Buscar estos eventos:
   - mysql_slave_status_seconds_behind_master = 999
   - mysql_slave_status_slave_io_running = 0
   - mysql_global_status_read_only cambios de 1 a 0
   - proxysql_mysql_monitor_connect_errors picos
```

---

## üîß Troubleshooting de Scripts

### Error: "Permission denied"
```bash
# Soluci√≥n: Dar permisos de ejecuci√≥n
chmod +x scripts/failover-promote-slave.sh
chmod +x scripts/failback-restore-master.sh
chmod +x scripts/check-replication-status.sh
```

### Error: "No se puede conectar a docker"
```bash
# Asegurar que el usuario puede ejecutar docker
sudo usermod -aG docker $USER
newgrp docker

# O ejecutar con sudo
sudo ./scripts/check-replication-status.sh
```

### Error: ".env no encontrado"
```bash
# Los scripts buscan .env relativo al proyecto
# Ejecutarlos desde la ra√≠z del proyecto:
cd /ruta/al/proyecto
./scripts/check-replication-status.sh

# NO desde dentro de scripts/:
cd scripts
./check-replication-status.sh  # ‚ùå Esto fallar√°
```

### Error: "Slave no est√° sincronizado"
```bash
# Si failback falla porque hay un lag grande
# 1. Esperar m√°s tiempo
sleep 60

# 2. Ejecutar nuevamente failback
./scripts/failback-restore-master.sh

# 3. Si sigue fallando, hacer failback manual:
docker compose exec db-slave mysql -u root -p${MYSQL_ROOT_PASSWORD} -e "SHOW MASTER STATUS\G"
docker compose exec db-master mysql -u root -p${MYSQL_ROOT_PASSWORD} -e "CHANGE REPLICATION SOURCE TO SOURCE_HOST='db-slave'..."
```

---

## Componente de Inteligencia Artificial

### Funcionalidad: Agente IA para Detecci√≥n de Brechas de Seguridad

#### ¬øQu√© hace?
El **AI Service** revisa continuamente los logs de acciones realizadas dentro de todos los microservicios y genera reportes autom√°ticos para el Administrador del Sistema cuando detecta:
- Intentos de acceso no autorizado
- Patrones an√≥malos de comportamiento
- Accesos fuera de horario
- M√∫ltiples intentos fallidos de login
- Actividad sospechosa en documentos sensibles

#### ¬øPor qu√© es √∫til para la licitaci√≥n?
La licitaci√≥n exige cumplir con:
- **Ley N¬∞19.628** sobre Protecci√≥n de la Vida Privada
- **ISO/IEC 27001** - Certificaci√≥n de Seguridad de la Informaci√≥n
- **RNF-2**: Protecci√≥n de informaci√≥n sensible de car√°cter judicial

El AI Service automatiza la vigilancia de seguridad, reduciendo el riesgo humano y proporcionando alertas tempranas de posibles vulnerabilidades.

#### Tecnolog√≠a
- **Modelo**: Llama2 (Ollama local)
- **An√°lisis**: Procesamiento de logs en tiempo real
- **Output**: Reportes en lenguaje natural para administradores

#### Endpoint de Ejemplo
```bash
POST /api/ai/analyze-security
{
  "service": "auth-service",
  "time_range": "last_24h"
}

Response:
{
  "status": "warning",
  "incidents": 3,
  "summary": "Se detectaron 3 intentos fallidos de login desde IP 192.168.1.100",
  "recommendation": "Considerar bloquear temporalmente esta IP"
}
```

---

## Instalaci√≥n y Uso

### Requisitos Previos
- **Docker Desktop**: Versi√≥n 20.10 o superior
- **RAM**: M√≠nimo 8GB (recomendado 16GB)
- **Espacio en disco**: 10GB libres
- **Sistema Operativo**: Windows 11, macOS, o Linux

### Paso 1: Clonar el Repositorio
```bash
git clone https://github.com/tu-usuario/sistema-causas-judiciales.git
cd sistema-causas-judiciales
```

### Paso 2: Configurar Variables de Entorno
```bash
# Copiar el template
cp .env.example .env

# Editar el archivo .env con credenciales
# Puedes usar VS Code:
code .env
```

**Variables importantes a configurar:**
- `MYSQL_ROOT_PASSWORD`: Contrase√±a del usuario root de MySQL
- `SMTP_USER` y `SMTP_PASSWORD`: Para env√≠o de notificaciones por email
- `OLLAMA_HOST`: URL de tu servidor Ollama (si usas IA local)

### Paso 3: Levantar el Sistema
```bash
# Construir e iniciar todos los servicios
docker-compose up -d

# Ver los logs en tiempo real
docker-compose logs -f

# Verificar que todos los servicios est√©n corriendo
docker-compose ps
```

### Paso 4: Acceder al Sistema

#### URLs de Acceso
- **Frontend**: http://localhost
- **API Gateway Dashboard**: http://localhost:8080
- **Grafana (Monitoreo)**: http://localhost:3000
- **Prometheus (M√©tricas)**: http://localhost:9090

#### Usuarios de Prueba (modificables)
| Rol | Usuario | Contrase√±a |
|-----|---------|-----------|
| Administrador | admin@judicial.cl | Admin123! |
| Abogado | abogado@judicial.cl | Abogado123! |

### Comandos √ötiles

#### Ver estado de servicios
```bash
docker-compose ps
```

#### Ver logs de un servicio espec√≠fico
```bash
docker-compose logs -f casos-service
```

#### Reiniciar un servicio
```bash
docker-compose restart casos-service
```

#### Detener todo el sistema
```bash
docker-compose down
```

#### Detener y eliminar todos los datos
```bash
docker-compose down -v
```

#### Ver m√©tricas de recursos
```bash
docker stats
```

---

## Sistema de Respaldos

## üìã Descripci√≥n

Sistema automatizado de respaldos para el proyecto de Causas Judiciales. Incluye scripts para respaldar y restaurar:

- **Base de datos MySQL** (esquema, datos, usuarios)
- **Archivos y documentos** (uploads de documentos judiciales)
- **Configuraciones del sistema** (docker-compose, .env, scripts)

---

## Uso R√°pido

### Respaldo Completo del Sistema

```bash
# Ejecutar respaldo completo (recomendado)
cd scripts/backup
./backup-all.sh
```

Este comando respaldar√° autom√°ticamente:
- ‚úÖ Base de datos completa
- ‚úÖ Todos los archivos cargados
- ‚úÖ Configuraciones del sistema
- ‚úÖ Scripts de administraci√≥n

### Respaldos Individuales

```bash
# Solo base de datos
./backup-db.sh

# Solo archivos
./backup-files.sh
```

---

## Scripts Disponibles

### 1. `backup-db.sh` - Respaldo de Base de Datos

**¬øQu√© hace?**
- Exporta toda la base de datos MySQL
- Comprime el archivo SQL con gzip
- Mantiene los √∫ltimos 7 d√≠as de respaldos
- Verifica la integridad del backup

**Uso:**
```bash
./backup-db.sh
```

**Salida:**
```
backups/database/
‚îú‚îÄ‚îÄ db_causas_judiciales_db_2024-11-02_14-30-00.sql.gz
‚îú‚îÄ‚îÄ db_causas_judiciales_db_2024-11-01_14-30-00.sql.gz
‚îî‚îÄ‚îÄ ...
```

**Configuraci√≥n:**
Puedes modificar estas variables en el script o en `.env`:
- `MYSQL_HOST`: Host de MySQL (default: `mysql`)
- `MYSQL_USER`: Usuario de MySQL (default: `admin_db`)
- `MYSQL_PASSWORD`: Contrase√±a
- `MYSQL_DATABASE`: Nombre de la BD (default: `causas_judiciales_db`)
- `BACKUP_RETENTION_DAYS`: D√≠as de retenci√≥n (default: `7`)

---

### 2. `restore-db.sh` - Para estaurar la Base de Datos

**¬øQu√© hace?**
- Lista backups disponibles
- Crea backup de seguridad antes de restaurar
- Restaura la base de datos desde un backup
- Verifica la restauraci√≥n

**Uso:**
```bash
# Ver backups disponibles
./restore-db.sh --list

# Restaurar el m√°s reciente
./restore-db.sh --latest

# Restaurar un backup espec√≠fico
./restore-db.sh db_causas_judiciales_db_2024-11-02_14-30-00.sql.gz
```

**‚ö†Ô∏è ADVERTENCIA:** Esta operaci√≥n SOBRESCRIBIR√Å la base de datos actual. Siempre crea un backup de seguridad antes de proceder.

**Proceso de restauraci√≥n:**
1. Verifica conectividad con MySQL
2. Crea backup de seguridad de la BD actual
3. Elimina la base de datos actual
4. Restaura desde el backup seleccionado
5. Verifica que la restauraci√≥n fue exitosa

---

### 3. `backup-files.sh` - Para Respaldo de Archivos

**¬øQu√© hace?**
- Respalda todos los archivos cargados (documentos judiciales)
- Crea un archivo tar.gz comprimido
- Mantiene los √∫ltimos 7 d√≠as de respaldos
- Verifica la integridad del backup

**Uso:**
```bash
./backup-files.sh
```

**Directorios respaldados:**
- `backend/documentos/uploads/` - Documentos cargados por usuarios

**Salida:**
```
backups/files/
‚îú‚îÄ‚îÄ files_2024-11-02_14-35-00.tar.gz
‚îú‚îÄ‚îÄ files_2024-11-01_14-35-00.tar.gz
‚îî‚îÄ‚îÄ ...
```

---

### 4. `restore-files.sh` - Para Restaurar Archivos

**¬øQu√© hace?**
- Lista backups de archivos disponibles
- Crea backup de seguridad de archivos actuales
- Restaura archivos desde un backup
- Verifica la restauraci√≥n

**Uso:**
```bash
# Ver backups disponibles
./restore-files.sh --list

# Restaurar el m√°s reciente
./restore-files.sh --latest

# Restaurar un backup espec√≠fico
./restore-files.sh files_2024-11-02_14-35-00.tar.gz
```

---

### 5. `backup-all.sh` - Para un Respaldo Completo

**¬øQu√© hace?**
- Ejecuta backup-db.sh
- Ejecuta backup-files.sh
- Respalda configuraciones (docker-compose.yml, .env.example, etc.)
- Respalda scripts de administraci√≥n
- Crea un archivo consolidado con todo
- Genera un MANIFEST con informaci√≥n del backup
- Mantiene los √∫ltimos 30 d√≠as de backups completos

**Uso:**
```bash
./backup-all.sh
```

**Salida:**
```
backups/complete/
‚îî‚îÄ‚îÄ backup_complete_2024-11-02_14-40-00.tar.gz
    ‚îú‚îÄ‚îÄ db_causas_judiciales_db_2024-11-02_14-40-00.sql.gz
    ‚îú‚îÄ‚îÄ files_2024-11-02_14-40-00.tar.gz
    ‚îú‚îÄ‚îÄ configs/
    ‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml
    ‚îÇ   ‚îú‚îÄ‚îÄ .env.example
    ‚îÇ   ‚îú‚îÄ‚îÄ monitoring/
    ‚îÇ   ‚îî‚îÄ‚îÄ scripts/
    ‚îî‚îÄ‚îÄ MANIFEST.txt
```

**Contenido del MANIFEST.txt:**
```
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë   MANIFIESTO DE RESPALDO COMPLETO      ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

INFORMACI√ìN DEL RESPALDO
========================
Fecha de creaci√≥n: 2024-11-02 14:40:00
Nombre del backup: backup_2024-11-02_14-40-00
Hostname: servidor-judicial
Usuario: admin

CONTENIDO DEL BACKUP
====================
- Base de datos (15.3 MB)
- Archivos documentos (234.7 MB)
- Configuraciones (2.1 MB)
- Scripts (0.5 MB)

Total: 252.6 MB
```

---

## üîÑ Automatizaci√≥n con Cron

### Configurar Backups Autom√°ticos

Para ejecutar backups autom√°ticamente, se pueden agrega estos trabajos a cron:

```bash
# Editar crontab
crontab -e

# Agregar estas l√≠neas:

# Backup completo diario a las 2 AM
0 2 * * * cd /ruta/al/proyecto/scripts/backup && ./backup-all.sh >> /var/log/backup.log 2>&1

# Backup de BD cada 6 horas
0 */6 * * * cd /ruta/al/proyecto/scripts/backup && ./backup-db.sh >> /var/log/backup-db.log 2>&1

# Backup de archivos cada 12 horas
0 */12 * * * cd /ruta/al/proyecto/scripts/backup && ./backup-files.sh >> /var/log/backup-files.log 2>&1
```

### Usando Docker Compose (Recomendado)

Ya incluimos un servicio de backup automatizado en `docker-compose.yml`:

```yaml
backup-service:
  build:
    context: ./scripts/backup
    dockerfile: Dockerfile.backup
  container_name: backup-service
  environment:
    - BACKUP_SCHEDULE=0 2 * * *  # Diario a las 2 AM
    - BACKUP_RETENTION_DAYS=7
  volumes:
    - ./backups:/backups
    - ./db:/db
    - ./backend:/backend
  networks:
    - app-network
  restart: unless-stopped
```

**Para cambiar la frecuencia**, edita `BACKUP_SCHEDULE` usando formato cron:
- `0 2 * * *` - Diario a las 2 AM
- `0 */6 * * *` - Cada 6 horas
- `0 0 * * 0` - Cada domingo a medianoche
- `*/30 * * * *` - Cada 30 minutos

---

## Estructura de Directorios de Backup

```
backups/
‚îú‚îÄ‚îÄ database/              # Backups de base de datos
‚îÇ   ‚îú‚îÄ‚îÄ db_causas_judiciales_db_2024-11-02_14-30-00.sql.gz
‚îÇ   ‚îú‚îÄ‚îÄ db_causas_judiciales_db_2024-11-01_14-30-00.sql.gz
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îú‚îÄ‚îÄ files/                 # Backups de archivos
‚îÇ   ‚îú‚îÄ‚îÄ files_2024-11-02_14-35-00.tar.gz
‚îÇ   ‚îú‚îÄ‚îÄ files_2024-11-01_14-35-00.tar.gz
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ
‚îî‚îÄ‚îÄ complete/              # Backups completos consolidados
    ‚îú‚îÄ‚îÄ backup_complete_2024-11-02_14-40-00.tar.gz
    ‚îú‚îÄ‚îÄ backup_complete_2024-11-01_14-40-00.tar.gz
    ‚îî‚îÄ‚îÄ ...
```

---

## Seguridad y Mejores Pr√°cticas

### Protecci√≥n de Backups

1. **Permisos restrictivos:**
```bash
chmod 700 backups/
chmod 600 backups/**/*.gz
```

2. **Excluir del control de versiones:**
Ya est√° configurado en `.gitignore`:
```
backups/
*.sql
*.sql.gz
*.tar.gz
```

3. **Encriptar backups sensibles:**
```bash
# Encriptar un backup
gpg --symmetric --cipher-algo AES256 backup_complete_2024-11-02.tar.gz

# Desencriptar
gpg --decrypt backup_complete_2024-11-02.tar.gz.gpg > backup.tar.gz
```

### Almacenamiento Externo

**Recomendaci√≥n:** Los backups deber√≠an copiarse a ubicaciones externas:

```bash
# Copiar a servidor remoto (SSH/SCP)
scp backups/complete/backup_complete_*.tar.gz user@servidor-backup:/backups/judicial/

# Copiar a almacenamiento en la nube (AWS S3)
aws s3 cp backups/complete/backup_complete_*.tar.gz s3://mi-bucket/backups/

# Copiar a Google Drive (usando rclone)
rclone copy backups/complete/ gdrive:Backups/Judicial/
```

---

## Verificaci√≥n de Backups

### Verificar Integridad

```bash
# Verificar un backup de BD
gunzip -t backups/database/db_*.sql.gz

# Verificar un backup de archivos
tar -tzf backups/files/files_*.tar.gz > /dev/null

# Verificar un backup completo
tar -tzf backups/complete/backup_complete_*.tar.gz > /dev/null
```

### Prueba de Restauraci√≥n

**Es cr√≠tico probar las restauraciones regularmente:**

```bash
# 1. Crear un entorno de prueba
docker-compose -f docker-compose.test.yml up -d

# 2. Restaurar el backup en el entorno de prueba
./restore-db.sh --latest

# 3. Verificar que los datos son correctos
docker exec mysql mysql -u admin_db -padmin -e "SELECT COUNT(*) FROM causas_judiciales_db.casos;"

# 4. Detener el entorno de prueba
docker-compose -f docker-compose.test.yml down
```

---

## üêõ Soluci√≥n de Posibles Problemas

### Error: "No se puede conectar a MySQL"

**Causa:** El contenedor de MySQL no est√° corriendo o no est√° listo.

**Soluci√≥n:**
```bash
# Verificar que MySQL est√© corriendo
docker-compose ps mysql

# Ver logs de MySQL
docker-compose logs mysql

# Reiniciar MySQL
docker-compose restart mysql

# Esperar a que est√© listo
docker-compose exec mysql mysqladmin ping -h localhost --silent
```

### Error: "Permission denied"

**Causa:** Los scripts no tienen permisos de ejecuci√≥n.

**Soluci√≥n:**
```bash
# Dar permisos de ejecuci√≥n
chmod +x scripts/backup/*.sh

# O todos los scripts
find scripts/ -name "*.sh" -exec chmod +x {} \;
```

### Error: "Backup corrupto"

**Causa:** El archivo se da√±√≥ durante la creaci√≥n o copia.

**Soluci√≥n:**
```bash
# Verificar integridad
gunzip -t backup.sql.gz

# Si est√° corrupto, eliminar y crear uno nuevo
rm backup.sql.gz
./backup-db.sh
```

### Espacio en disco insuficiente

**S√≠ntoma:** Backups fallan con errores de espacio.

**Soluci√≥n:**
```bash
# Ver espacio disponible
df -h

# Ver tama√±o de backups
du -sh backups/

# Limpiar backups antiguos manualmente
find backups/ -type f -mtime +30 -delete

# Reducir per√≠odo de retenci√≥n en los scripts
# Editar BACKUP_RETENTION_DAYS=3
```

---

## Ejemplos de Uso

### Escenario 1: Backup Diario Antes de Actualizaci√≥n

```bash
#!/bin/bash
# Script para actualizar el sistema con backup previo

echo "Creando backup antes de actualizar..."
cd scripts/backup
./backup-all.sh

echo "Actualizando sistema..."
cd ../..
git pull
docker-compose build
docker-compose up -d

echo "Actualizaci√≥n completada. Backup disponible en backups/complete/"
```

### Escenario 2: Migraci√≥n a Nuevo Servidor

```bash
# En el servidor antiguo:
./backup-all.sh
BACKUP=$(ls -t backups/complete/backup_complete_*.tar.gz | head -n 1)
scp $BACKUP nuevo-servidor:/tmp/

# En el servidor nuevo:
cd /ruta/proyecto
tar -xzf /tmp/backup_complete_*.tar.gz
cd scripts/backup
./restore-db.sh --latest
./restore-files.sh --latest
```

### Escenario 3: Recuperaci√≥n de Desastre

```bash
# Si la base de datos se corrompe
./restore-db.sh --latest

# Si se eliminaron archivos por error
./restore-files.sh --latest

# Si el sistema completo fall√≥
tar -xzf backups/complete/backup_complete_<fecha>.tar.gz
# Restaurar cada componente individualmente
```

---

## Soporte

Para problemas con los scripts de backup:

1. Revisar los logs: `docker-compose logs backup-service`
2. Verificar permisos: `ls -la scripts/backup/`
3. Compruebar espacio: `df -h`
4. Consultar este README
5. Contactar al administrador del sistema

---

## Changelog

### Versi√≥n 1.0.0 (2024-11-02)
- ‚úÖ Script inicial de backup de BD
- ‚úÖ Script de restauraci√≥n de BD
- ‚úÖ Script de backup de archivos
- ‚úÖ Script de restauraci√≥n de archivos
- ‚úÖ Script de backup completo
- ‚úÖ Automatizaci√≥n con cron
- ‚úÖ Documentaci√≥n completa

---

## Monitoreo del Sistema

### Acceso a Grafana
1. Abrir http://localhost:3000
2. Login: `admin` / `admin123`
3. Dashboard: "Sistema Causas Judiciales"

### M√©tricas Monitoreadas
- ‚úÖ CPU y memoria de cada servicio
- ‚úÖ Tasa de peticiones por segundo
- ‚úÖ Tiempo de respuesta de APIs
- ‚úÖ Estado de salud de bases de datos
- ‚úÖ Uso de cach√© (Redis)
- ‚úÖ Espacio en disco

### Alertas Configuradas
- CPU > 80% por m√°s de 5 minutos
- Memoria > 90%
- Servicio ca√≠do
- Base de datos no responde
- Backup fallido

---

## Testing y Validaci√≥n

### Health Checks
Todos los servicios tienen endpoints de salud:
```bash
# Frontend
curl http://localhost/health

# Auth Service
curl http://localhost/api/auth/health

# Casos Service
curl http://localhost/api/casos/health
```

### Prueba de Alta Disponibilidad
```bash
# 1. Verificar que todo funciona
docker-compose ps

# 2. Simular falla del MySQL Master
docker-compose stop mysql-master

# 3. Verificar que el sistema sigue funcionando
curl http://localhost/api/casos

# 4. Levantar nuevamente el Master
docker-compose start mysql-master
```
---

## Troubleshooting

### Problema: Servicios no inician
```bash
# Ver logs detallados
docker-compose logs

# Verificar puertos en uso
netstat -an | grep LISTEN

# Limpiar y reiniciar
docker-compose down -v
docker-compose up -d
```

### Problema: Base de datos no conecta
```bash
# Verificar que MySQL est√© corriendo
docker-compose ps mysql-master

# Ver logs de MySQL
docker-compose logs mysql-master

# Conectar manualmente para probar
docker exec -it mysql-master mysql -u root -p
```

### Problema: Frontend muestra error 502
```bash
# Verificar que el gateway est√© corriendo
docker-compose ps gateway

# Reiniciar el gateway
docker-compose restart gateway
```

---

## üìö Recursos Adicionales

- [Documentaci√≥n de Docker Compose](https://docs.docker.com/compose/)
- [Traefik Documentation](https://doc.traefik.io/traefik/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [React Documentation](https://react.dev/)
- [MySQL Replication Guide](https://dev.mysql.com/doc/refman/8.0/en/replication.html)

---

## üìÑ Licencia

Este proyecto fue desarrollado como parte del curso de Administraci√≥n de Redes y Sistemas Computacionales de la Universidad de Talca.

---

## Contacto

Para preguntas sobre el proyecto:
- Camilo Fuentes: [email]
- Demian Maturana: [email]
- Catalina Herrera: [email]

**Profesor**: Ricardo P√©rez (riperez@utalca.cl)

---

## Para ejecutar

docker-compose build
docker-compose up
escribir en el navegador https://locahost:8081/

---

## Inicializaci√≥n de la Base de Datos con Replicaci√≥n Segura

El sistema est√° configurado para levantar un cluster de base de datos MySQL con replicaci√≥n maestro-esclavo (source-replica) segura (v√≠a SSL) y de forma totalmente automatizada.

Sigue estos pasos para la inicializaci√≥n:

### 1. Configurar Variables de Entorno

Copia el archivo de ejemplo `.env.example` a un nuevo archivo llamado `.env`.

```bash
cp .env.example .env
```

Abre el archivo `.env` y ajusta las contrase√±as y otros valores seg√∫n sea necesario.

### 2. Generar Certificados SSL

Para la comunicaci√≥n segura entre el maestro y el esclavo de la base de datos, se requieren certificados SSL. Se proporciona un script para generarlos autom√°ticamente.

Primero, dale permisos de ejecuci√≥n al script:

```bash
chmod +x db/generate-certs.sh
```

Luego, ejec√∫talo:

```bash
./db/generate-certs.sh
```

Esto crear√° todos los archivos necesarios en el directorio `db/certs`.

### 3. Levantar los Servicios

Con los certificados y las variables de entorno listas, puedes levantar todo el stack de servicios.

> **Nota**: Si has tenido ejecuciones anteriores, es recomendable limpiar los vol√∫menes de Docker para asegurar una inicializaci√≥n limpia con la nueva configuraci√≥n de SSL. Para ello, ejecuta `docker compose down -v` antes de continuar.

```bash
docker compose up -d --build
```

### 4. Verificar la Replicaci√≥n

Despu√©s de que los contenedores se hayan iniciado (dale un minuto), puedes verificar que la replicaci√≥n est√° funcionando correctamente. Ejecuta el siguiente comando:

```bash
docker compose exec db-slave mysql -u root -p${MYSQL_ROOT_PASSWORD:-root} -e "SHOW REPLICA STATUS\G"
```

En la salida, busca las siguientes l√≠neas. Ambas deben indicar `Yes`:

```
Replica_IO_Running: Yes
Replica_SQL_Running: Yes
```

Si es as√≠, la base de datos est√° operando en modo de alta disponibilidad con replicaci√≥n segura.
---

## üöÄ Sistema de Configuraci√≥n Din√°mica

Este proyecto utiliza **contenedores Alpine Linux** para generar archivos de configuraci√≥n din√°micamente desde templates, usando variables de entorno.

### Configuraci√≥n R√°pida

1. **Copia el archivo de ejemplo de variables:**
```bash
cp .env.example .env
```

2. **Edita las variables seg√∫n tu entorno:**
```bash
nano .env  # O tu editor preferido
```

3. **Inicia el sistema (las configs se generan autom√°ticamente):**
```bash
docker-compose up -d
```

### Gesti√≥n de Configuraciones

Usa el script de gesti√≥n para controlar las configuraciones:

```bash
# Ver estado de inicializaci√≥n
./scripts/manage-configs.sh status

# Ver logs de generaci√≥n de configs
./scripts/manage-configs.sh logs

# Regenerar configuraciones despu√©s de cambiar .env
./scripts/manage-configs.sh clean
docker-compose up -d
```

### Servicios con Configuraci√≥n Din√°mica

- **Prometheus** - M√©tricas y monitoreo
- **Redis** - Cach√© con autenticaci√≥n
- **ProxySQL** - Routing de base de datos
- **Traefik** - API Gateway

üìñ **Documentaci√≥n completa:** [docs/CONFIG-INIT-SYSTEM.md](docs/CONFIG-INIT-SYSTEM.md)

---

## üìò Conceptos Clave: Failover

### Failover
- Proceso de conmutaci√≥n autom√°tica/manual a un servidor de respaldo cuando el servidor principal falla.
- Objetivo: Minimizar el tiempo de inactividad.
- Tipo: Puede ser **autom√°tico** (mediante orquestaci√≥n) o **manual** (asistido por scripts).

### Failback
- Proceso inverso al failover: retorno del servicio al servidor principal una vez recuperado.
- Debe realizarse de forma ordenada y validada.
- Riesgo: P√©rdida de datos si no se sincroniza correctamente.

### Check (Verificaci√≥n)
- Validaci√≥n continua del estado de los servicios.
- Detecci√≥n de fallos.
- Confirmaci√≥n de sincronizaci√≥n entre instancias primaria y secundaria.

---

## Arquitectura de Failover

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Cliente (Frontend)                        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  Traefik/LB    ‚îÇ
         ‚îÇ  (API Gateway) ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ            ‚îÇ            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Primary‚îÇ  ‚îÇSecondary‚îÇ  ‚îÇTertiary‚îÇ
‚îÇ Server ‚îÇ  ‚îÇ Server  ‚îÇ  ‚îÇ Server ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚îÇ            ‚îÇ            ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                 ‚îÇ
         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
         ‚îÇ  MySQL Cluster ‚îÇ
         ‚îÇ  (Replication) ‚îÇ
         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## Scripts Disponibles: Failover

### 1. `check_health.sh` - Health Check Script

**Ubicaci√≥n**: `scripts/failover/check_health.sh`

**Descripci√≥n**: Script para monitorear la salud general del sistema de replicaci√≥n MySQL.

**Uso b√°sico**:
```bash
chmod +x scripts/failover/check_health.sh
./scripts/failover/check_health.sh [--verbose] [--webhook <url>]
```

**Opciones**:
- `--verbose`: Salida detallada
- `--webhook`: URL para notificaciones en webhooks

**¬øQu√© verifica?**
- ‚úÖ Estado de conectividad de los servicios principales
- ‚úÖ Disponibilidad de la base de datos
- ‚úÖ Estado del cach√© Redis
- ‚úÖ Latencia de respuesta
- ‚úÖ Replicaci√≥n sincronizada

**Salida esperada**:
```
==========================================
HEALTH CHECK - Sistema de Causas Judiciales
==========================================

‚úÖ Frontend: Healthy (127.0.0ms)
‚úÖ Backend API: Healthy (45ms)
‚úÖ MySQL Master: Healthy (2ms)
‚úÖ MySQL Replica: Healthy (3ms)
‚úÖ Redis: Healthy (1ms)

REPLICATION STATUS:
Slave_IO_Running: Yes
Slave_SQL_Running: Yes
Seconds_Behind_Master: 0

‚úÖ SISTEMA OPERACIONAL - No se requiere acci√≥n
```

---

### 2. `do_failover.sh` - Ejecutar Failover

**Ubicaci√≥n**: `scripts/failover/do_failover.sh`

**Descripci√≥n**: Script para promover manualmente el Replica como nuevo Master (ejecutar failover manual).

**Uso**:
```bash
chmod +x scripts/failover/do_failover.sh
./scripts/failover/do_failover.sh <primary_host> <secondary_host> [--force] [--no-verify]
```

**Opciones**:
- `--force`: Forzar failover sin confirmaci√≥n
- `--no-verify`: Omitir verificaciones post-failover

**Ejemplo**:
```bash
./scripts/failover/do_failover.sh db-master db-slave --force
```

**Proceso que ejecuta**:
1. Validaci√≥n de prerrequisitos
2. Sincronizaci√≥n de datos pendientes
3. Activaci√≥n del servidor secundario
4. Actualizaci√≥n de la configuraci√≥n de Traefik
5. Redirecci√≥n de tr√°fico
6. Validaci√≥n post-failover

**Salida esperada**:
```
==========================================
EJECUTANDO FAILOVER
==========================================

‚úì Validando conexi√≥n a db-master... OFFLINE
‚úì Validando conexi√≥n a db-slave... ONLINE
‚úì Sincronizando datos pendientes...
‚úì Deteniendo replicaci√≥n en db-slave...
‚úì Promoviendo db-slave como nuevo Master...
‚úì Actualizando Traefik...
‚úì Redirigiendo tr√°fico...

‚úÖ FAILOVER COMPLETADO
   Nuevo Master: db-slave
   Replicaci√≥n pausada hasta recuperaci√≥n del primario
```

---

### 3. `check_failover_status.sh` - Verificar Estado

**Ubicaci√≥n**: `scripts/failover/check_failover_status.sh`

**Descripci√≥n**: Script para verificar el estado actual del failover y replicaci√≥n.

**Uso**:
```bash
chmod +x scripts/failover/check_failover_status.sh
./scripts/failover/check_failover_status.sh [--json]
```

**Opciones**:
- `--json`: Salida en formato JSON para integraci√≥n

**Salida esperada (texto)**:
```
==========================================
ESTADO DEL FAILOVER
==========================================

MASTER ACTUAL: db-slave
REPLICA: db-master (OFFLINE - Esperando recuperaci√≥n)

ESTADO DE REPLICACI√ìN:
  IO Thread: Stopped (Esperando master)
  SQL Thread: Stopped

DATOS:
  Tablas sincronizadas: 25/25
  √öltimas transacciones: 1500
  Lag de replicaci√≥n: N/A

SERVICIOS:
  Frontend: OK
  Auth Service: OK
  Casos Service: OK
  Documentos Service: OK
```

**Salida esperada (JSON)**:
```json
{
  "status": "active_failover",
  "master": "db-slave",
  "replica": "db-master",
  "replica_status": "offline",
  "replication": {
    "io_thread": "stopped",
    "sql_thread": "stopped",
    "lag_seconds": null
  },
  "services": {
    "frontend": "healthy",
    "api": "healthy"
  }
}
```

---

## Procedimiento Completo: Failover y Failback

### Escenario: Master falla durante producci√≥n

#### Paso 1: Detecci√≥n autom√°tica (autom√°tico)
```bash
failover-daemon detecta ca√≠da de db-master
‚Üí Ejecuta do_failover.sh autom√°ticamente
‚Üí db-slave se promueve como nuevo Master
```

#### Paso 2: Verificar estado (manual)
```bash
./scripts/failover/check_failover_status.sh

# Confirmar que db-slave ahora es Master
# Todos los servicios deben estar operacionales
```

#### Paso 3: Reparar Master original (operacional)
```bash
# Ejemplo: reiniciar db-master
docker compose restart db-master

# Esperar a que est√© listo
sleep 30

# Verificar que est√° disponible
./scripts/failover/check_health.sh --verbose
```

#### Paso 4: Ejecutar Failback (manual)
```bash
# Restaurar configuraci√≥n original
./scripts/failback/do_failback.sh db-master db-slave

# El script:
# 1. Valida estado del db-master recuperado
# 2. Sincroniza datos desde db-slave
# 3. Reconecta db-master como Replica
# 4. Promueve db-master a Master
# 5. Actualiza Traefik
```

#### Paso 5: Verificar integridad (manual)
```bash
# Confirmar estado final
./scripts/failover/check_failover_status.sh

# Debe mostrar:
# MASTER ACTUAL: db-master
# REPLICA: db-slave (ONLINE)
# Replicaci√≥n normal
```

---

## Monitoreo y Validaci√≥n

### Puntos de Control Cr√≠ticos

1. **Base de Datos**
   - ‚úÖ Replicaci√≥n sincronizada
   - ‚úÖ Sin error de replicaci√≥n
   - ‚úÖ Consistencia de datos verificada

2. **Servicios Backend**
   - ‚úÖ Todos los microservicios en estado "healthy"
   - ‚úÖ Sin errores de conexi√≥n
   - ‚úÖ Latencia dentro de l√≠mites

3. **Frontend**
   - ‚úÖ Accesible desde navegador
   - ‚úÖ Sesiones activas preservadas
   - ‚úÖ Sin errores de consola

4. **Cache Redis**
   - ‚úÖ Conectividad activa
   - ‚úÖ TTL de keys preservado
   - ‚úÖ Sin p√©rdida de sesiones

### M√©tricas Monitoreadas

```
Sistema de Alertas:
‚îú‚îÄ‚îÄ CPU > 80% ‚Üí Investigar
‚îú‚îÄ‚îÄ Memoria > 85% ‚Üí Investigar
‚îú‚îÄ‚îÄ Latencia DB > 200ms ‚Üí Cr√≠tico
‚îú‚îÄ‚îÄ Replicaci√≥n lag > 5s ‚Üí Cr√≠tico
‚îú‚îÄ‚îÄ Conexiones rechazadas ‚Üí Cr√≠tico
‚îî‚îÄ‚îÄ Errores 5xx > 1% ‚Üí Cr√≠tico
```

### Ver eventos en Grafana

```bash
# 1. Acceder a Grafana
http://localhost:3000

# 2. Ir a Dashboard ‚Üí "Base de Datos - Replicaci√≥n"

# 3. Buscar estos eventos:
   - mysql_slave_status_seconds_behind_master
   - mysql_slave_status_slave_io_running
   - mysql_global_status_read_only
   - proxysql_mysql_monitor_connect_errors
```

---

## Troubleshooting: Failover

### Problema: Failover Lento

**S√≠ntomas**:
- Tiempo de conmutaci√≥n > 5 minutos
- Usuarios reportan desconexiones prolongadas

**Causas Posibles**:
1. Sincronizaci√≥n de datos incompleta
2. Cierre gradual de conexiones lento

**Soluci√≥n**:
```bash
# Aumentar agresividad de sincronizaci√≥n
export FAILOVER_TIMEOUT=300

# Forzar cierre de conexiones antiguas
docker compose exec db-proxy mysql -e "KILL QUERY ALL"

# Ejecutar failover nuevamente
./scripts/failover/do_failover.sh db-master db-slave --force
```

### Problema: P√©rdida de Datos

**S√≠ntomas**:
- Transacciones no registradas
- Inconsistencia entre servidores

**Causas Posibles**:
1. Replicaci√≥n no sincronizada
2. Transacciones en curso durante failover

**Soluci√≥n**:
```bash
# Validar integridad
./scripts/failover/check_health.sh --verbose

# Esperar sincronizaci√≥n completa
while [ $(./scripts/failover/check_failover_status.sh --json | grep "lag_seconds" | grep -v null) ]; do
  sleep 5
done

# Luego ejecutar failover
./scripts/failover/do_failover.sh db-master db-slave
```

### Problema: Failback Fallido

**S√≠ntomas**:
- Script retorna error
- Servidor primario no activa

**Causas Posibles**:
1. Servidor primario a√∫n no recuperado
2. Problemas de sincronizaci√≥n

**Soluci√≥n**:
```bash
# Verificar estado del primario
./scripts/failover/check_health.sh

# Si hay errores, esperar m√°s
sleep 60 && ./scripts/failover/check_health.sh

# Luego ejecutar failback
./scripts/failback/do_failback.sh db-master db-slave

# Si persiste, contactar soporte y revisar logs:
docker compose logs failover-daemon | tail -50
```

### Problema: ProxySQL no reconoce cambios

**S√≠ntomas**:
- Las aplicaciones siguen apuntando al antiguo master
- Tr√°fico no se redirige

**Soluci√≥n**:
```bash
# Reiniciar ProxySQL
docker compose restart db-proxy

# Esperar a que reconecte
sleep 10

# Verificar status
./scripts/failover/check_failover_status.sh
```

---

## Checklist de Failover

### ‚úÖ Antes de Failover
- [ ] Notificar al equipo y usuarios
- [ ] Crear ticket de incidente
- [ ] Ejecutar `./scripts/failover/check_health.sh`
- [ ] Verificar backups recientes
- [ ] Confirmar servidor secundario est√° listo

### ‚öôÔ∏è Durante Failover
- [ ] Ejecutar `./scripts/failover/do_failover.sh`
- [ ] Monitorear logs en tiempo real: `docker compose logs -f failover-daemon`
- [ ] Verificar alertas en Grafana
- [ ] Validar estado post-failover: `./scripts/failover/check_failover_status.sh`

### ‚úÖ Despu√©s de Failover
- [ ] Confirmar servicios operativos
- [ ] Probar funcionalidades cr√≠ticas
- [ ] Notificar al usuario
- [ ] Documentar incidente

---

## Checklist de Failback

### ‚úÖ Antes de Failback
- [ ] Servidores primario completamente recuperado
- [ ] Ejecutar `./scripts/failover/check_health.sh`
- [ ] Datos sincronizados al 100%
- [ ] Ventana de mantenimiento confirmada
- [ ] Equipo de soporte disponible
- [ ] Backups actuales realizados

### ‚öôÔ∏è Durante Failback
- [ ] Ejecutar `./scripts/failback/do_failback.sh`
- [ ] Monitorear durante transici√≥n: `docker compose logs -f failover-daemon`
- [ ] Estar listo para rollback: `./scripts/failover/do_failover.sh` (revertir)

### ‚úÖ Despu√©s de Failback
- [ ] Verificar servicios normalizados: `./scripts/failover/check_failover_status.sh`
- [ ] Probar todas las funcionalidades
- [ ] Validar replicaci√≥n secundaria est√° activa
- [ ] Documentar resultados
- [ ] Revisar logs para anomal√≠as: `docker compose logs failover-daemon | grep -i error`

---

## Flujo R√°pido de Referencia

```bash
# 1. DETECTAR PROBLEMA
./scripts/check-replication-status.sh

# 2. SI MASTER EST√Å DOWN, EJECUTAR FAILOVER
sudo ./scripts/failover-promote-slave.sh -y

# 3. VERIFICAR ESTADO
./scripts/check-replication-status.sh

# 4. CUANDO MASTER SE RECUPERA, EJECUTAR FAILBACK
sudo ./scripts/failback-restore-master.sh -y

# 5. VERIFICAR VUELTA A NORMAL
./scripts/check-replication-status.sh
```

---

## üéØ Scripts Principales (Producci√≥n)

### 1. `check-replication-status.sh` - Verificar Estado

**Ubicaci√≥n**: `scripts/check-replication-status.sh`

**Descripci√≥n**: Verifica la salud general del sistema de replicaci√≥n MySQL y ProxySQL.

**Uso**:
```bash
./scripts/check-replication-status.sh
```

**¬øQu√© verifica?**
- ‚úÖ Estado de ProxySQL (hostgroups, servidor)
- ‚úÖ Pool de conexiones
- ‚úÖ Estado del Master (hostname, server_id, read_only)
- ‚úÖ Estado de replicaci√≥n del Slave
- ‚úÖ GTID sincronizados

**Salida esperada (sistema saludable)**:
```
==========================================
Database Replication Health Check
==========================================

=== ProxySQL Server Status ===
hostgroup_id | hostname  | port | status | weight | max_connections
10           | db-master | 3306 | ONLINE | 1      | 100
20           | db-master | 3306 | ONLINE | 1      | 100
20           | db-slave  | 3306 | ONLINE | 1      | 100

=== DB Master Status ===
hostname | server_id | read_only | super_read_only
db-master| 1        | 0         | 0

=== DB Slave Replication Status ===
SERVICE_STATE: ON
LAST_ERROR_MESSAGE: (vac√≠o)

=== GTID Status ===
Master GTID: a1b2c3d4:1-1000
Slave GTID:  a1b2c3d4:1-1000
```

---

### 2. `failover-promote-slave.sh` - Ejecutar Failover

**Ubicaci√≥n**: `scripts/failover-promote-slave.sh`

**Descripci√≥n**: Promueve el Slave como nuevo Master autom√°ticamente.

**Uso**:
```bash
# Con confirmaci√≥n interactiva
sudo ./scripts/failover-promote-slave.sh

# Sin confirmaci√≥n (modo autom√°tico)
sudo ./scripts/failover-promote-slave.sh -y
```

**Opciones**:
- `-y`: Ejecutar sin confirmaci√≥n interactiva

**Variables de entorno (.env)**:
```bash
OLD_MASTER=db-master
NEW_MASTER=db-slave
PROXYSQL_CONTAINER=db-proxy
PROXYSQL_ADMIN_USER=admin
PROXYSQL_ADMIN_PASSWORD=admin
MYSQL_ROOT_PASSWORD=tu_contrase√±a
MYSQL_REPLICATION_USER=replicator
MYSQL_REPLICATION_PASSWORD=tu_contrase√±a
```

**Proceso que ejecuta**:
1. Bloquea escrituras en el master antiguo
2. Detiene replicaci√≥n en el slave
3. Promueve slave como nuevo master
4. Actualiza ProxySQL (hostgroup 10 y 20)
5. Verifica funcionamiento

**Ejemplo de ejecuci√≥n**:
```bash
$ sudo ./scripts/failover-promote-slave.sh -y

==========================================
ProxySQL Failover: Promote Slave to Master
==========================================

Verificando estado actual de ProxySQL...
hostgroup_id | hostname  | status
10           | db-master | ONLINE
20           | db-slave  | ONLINE

Modo autom√°tico: procediendo sin confirmaci√≥n

Paso 1: Deteniendo escrituras en antiguo master (db-master)...
Paso 2: Desactivando replicaci√≥n en db-slave y habilitando writes...
Paso 3: Reconfigurando ProxySQL...

‚úÖ Failover completado:
   - Nuevo Master: db-slave (hostgroups 10 y 20)
   - Antiguo Master: db-master (OFFLINE en ambos hostgroups)

‚ö†Ô∏è  Pr√≥ximos pasos:
   1. Verificar conectividad de aplicaciones
   2. Monitorear logs: docker logs -f db-proxy
   3. Planificar failback cuando el antiguo master est√© disponible
```

---

### 3. `failback-restore-master.sh` - Ejecutar Failback

**Ubicaci√≥n**: `scripts/failback-restore-master.sh`

**Descripci√≥n**: Restaura el master original y revierte la configuraci√≥n.

**Uso**:
```bash
# Con confirmaci√≥n interactiva en cada paso
sudo ./scripts/failback-restore-master.sh

# Sin confirmaci√≥n (modo autom√°tico)
sudo ./scripts/failback-restore-master.sh -y
```

**Opciones**:
- `-y`: Ejecutar sin confirmaci√≥n interactiva

**Variables de entorno (.env)**:
```bash
ORIGINAL_MASTER=db-master
CURRENT_MASTER=db-slave
PROXYSQL_CONTAINER=db-proxy
PROXYSQL_ADMIN_USER=admin
PROXYSQL_ADMIN_PASSWORD=admin
MYSQL_ROOT_PASSWORD=tu_contrase√±a
MYSQL_REPLICATION_USER=replicator
MYSQL_REPLICATION_PASSWORD=tu_contrase√±a
```

**Proceso que ejecuta**:
1. Configura master original como replica del actual
2. Espera sincronizaci√≥n completa (2+ confirmaciones GTID)
3. Bloquea escrituras en master actual
4. Promueve master original nuevamente
5. Configura master actual como replica
6. Actualiza ProxySQL

**Ejemplo de ejecuci√≥n**:
```bash
$ sudo ./scripts/failback-restore-master.sh -y

==========================================
ProxySQL Failback: Restore Original Master
==========================================

Verificando estado actual de ProxySQL...
hostgroup_id | hostname  | status
20           | db-slave  | ONLINE

Modo autom√°tico: procediendo sin confirmaci√≥n

Paso 1: Reconfigurando db-master como slave...
‚úÖ Replicaci√≥n activa

Paso 2: Verificando replicaci√≥n...
‚úÖ Replicaci√≥n activa

Paso 3: Esperando sincronizaci√≥n completa...
‚úÖ Sincronizaci√≥n confirmada (1/2)
‚úÖ Sincronizaci√≥n confirmada (2/2)
‚úÖ db-master est√° completamente sincronizado con GTIDs id√©nticos

[Pasos 4-7: Sincronizaci√≥n y promoci√≥n...]

Paso 8: Reconfigurando ProxySQL...

‚úÖ Failback completado:
   - Master restaurado: db-master (hostgroup 10)
   - Slave: db-slave (hostgroup 20)

‚ö†Ô∏è  Verificar:
   1. Conectividad de aplicaciones
   2. Replicaci√≥n: docker exec db-slave mysql -u root -p -e "SHOW REPLICA STATUS\G"
   3. Logs ProxySQL: docker logs -f db-proxy
```

---

## ‚ö†Ô∏è Diferencias de Scripts

| Script | Ubicaci√≥n | Cuando usarlo | Requiere |
|--------|-----------|---------------|----------|
| **check-replication-status.sh** | `scripts/` | Verificar estado | Lectura |
| **failover-promote-slave.sh** | `scripts/` | Master est√° DOWN | sudo |
| **failback-restore-master.sh** | `scripts/` | Master recuperado | sudo |
| check_health.sh | `scripts/failover/` | Health check completo | Lectura |
| do_failover.sh | `scripts/failover/` | Failover manual avanzado | sudo |
| prepare_failback.sh | `scripts/failback/` | Pre-validaci√≥n failback | Lectura |
| do_failback.sh | `scripts/failback/` | Failback avanzado | sudo |
| verify_failback.sh | `scripts/failback/` | Post-validaci√≥n | Lectura |

---

## üö® Casos de Uso Pr√°cticos

### Caso 1: Master Falla Inesperadamente

```bash
# 1. Verificar qu√© pas√≥
./scripts/check-replication-status.sh

# 2. Ver que db-master est√° DOWN
# ‚ùå db-master no est√° corriendo

# 3. Ejecutar failover inmediatamente
sudo ./scripts/failover-promote-slave.sh -y

# 4. Verificar que sistema est√° UP con nuevo master
./scripts/check-replication-status.sh
# Debe mostrar: db-slave en hostgroup 10 (ONLINE)

# 5. Notificar al equipo
# "Master falla. Failover a db-slave completado. Sistema UP."
```

### Caso 2: Master Se Recupera, Hacer Failback

```bash
# 1. Verificar estado actual
./scripts/check-replication-status.sh
# Muestra: db-slave es master actual

# 2. Confirmar que master original est√° listo
docker compose ps db-master
# CONTAINER ID | STATUS: Up X seconds

# 3. Ejecutar failback
sudo ./scripts/failback-restore-master.sh -y

# 4. Verificar restauraci√≥n
./scripts/check-replication-status.sh
# Debe mostrar: db-master en hostgroup 10 (ONLINE)

# 5. Confirmar con aplicaciones
curl http://localhost/api/casos
# Debe responder OK
```

### Caso 3: Verificaci√≥n Regular (Health Check)

```bash
# Ejecutar cada 4 horas o seg√∫n SLA
0 */4 * * * cd /path/to/proyecto && ./scripts/check-replication-status.sh | tee -a /var/log/replication-check.log

# Si hay problemas:
# - Enviar alerta a equipo
# - Revisar logs: docker compose logs failover-daemon
# - Contactar DevOps
```

---

